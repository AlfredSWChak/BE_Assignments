sum_mu_less_0 <- sum(b_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
b_pValue <- twosided_pvalue(sum_mu_greater_0, sum_mu_less_0)
print(paste('The two-sided p-value is:',b_pValue))
print('Gibbs sampling in case of normal prior distribution for µ')
c_prior_mean <- 0.5
c_prior_variance <- 0.25^2
c_result <- gibbsSampling_normalPrior(sampleData, c_prior_mean, c_prior_variance)
# Trace plot of µ
df <- data.frame(draw = seq_along(c_result$mu), mu = c_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of normal prior distribution for µ where m_prior = 0.5, v_prior = 0.0625)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/c_normalPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(c_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(c_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
c_pValue <- twosided_pvalue(sum_mu_greater_0, sum_mu_less_0)
print(paste('The two-sided p-value is:',c_pValue))
twoSidedTest <- function(input_t) {
if (input_t > -2.2622 & input_t < 2.2622) {
print('t ∈ [-2.2622, 2.2622]: Do not reject the null.')
} else {
print('t ∉ [-2.2622, 2.2622]: Reject the null.')
}
}
t_statistic <- mean(sampleData) / sqrt(var(sampleData)/length(sampleData))
print('A classical/frequentist two-sided test:')
print(paste('Test statistic:', round(t_statistic,4)))
print(paste('The p-value is:', round(t.test(sampleData, alternative = 'two.sided')$p.value,4)))
twoSidedTest(t_statistic)
twoSidedTest <- function(input_t) {
if (input_t > -2.2622 & input_t < 2.2622) {
print('t ∈ [-2.2622, 2.2622]: Do not reject the null.')
} else {
print('t ∉ [-2.2622, 2.2622]: Reject the null.')
}
}
t_statistic <- mean(sampleData) / sqrt(var(sampleData)/length(sampleData))
print('A classical/frequentist two-sided test:')
print(paste('Test statistic:', round(t_statistic,4)))
print(paste('The p-value is:', round(t.test(sampleData, alternative = 'two.sided')$p.value,4)))
twoSidedTest(t_statistic)
t.test(sampleData, alternative = 'two.sided')
print('Gibbs sampling in case of flat prior distribution for µ')
sampleData <- c(1.6088,-1.4579,0.4502,1.0701,-0.3803,1.1201,0.4199,0.3998,-0.1904,0.3932)
numberOfSimulations <- 11000
numberOfBurnIn <- 1000
gibbsSampling_flatPrior <- function(input_sample){
h_list <- numeric(numberOfSimulations)
mu_list <- numeric(numberOfSimulations)
initial_mu <- mean(input_sample)
numberOfSample <- length(input_sample)
# Gibbs sampling
for (i in 1:numberOfSimulations) {
a <- numberOfSample / 2
if (i-1 == 0){
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - initial_mu)^2)))
} else {
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - mu_list[i-1])^2)))
}
bar_y <- mean(sampleData)
# draw from Gamma distribution
h_list[i] <- rgamma(n = 1, shape = a, rate = b)
# draw from Normal distribution
mu_list[i] <- rnorm(n = 1, mean = bar_y,
sd = sqrt(1/(h_list[i] * numberOfSample)))
}
return(list(h=h_list, mu=mu_list))
}
a_result <- gibbsSampling_flatPrior(sampleData)
# Trace plot of µ
library(ggplot2)
df <- data.frame(draw = seq_along(a_result$mu), mu = a_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of flat prior distribution for µ)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/a_flatPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
twosided_pvalue <- function(p_pos, p_neg) {
result <- 2 * min(p_pos, p_neg)
result <- min(result, 1)
return(result)
}
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(a_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(a_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
a_pValue <- twosided_pvalue(sum_mu_greater_0, sum_mu_less_0)
print(paste('The two-sided p-value is:',a_pValue))
print('Gibbs sampling in case of normal prior distribution for µ')
gibbsSampling_normalPrior <- function(input_sample, prior_mean, prior_variance){
h_list <- numeric(numberOfSimulations)
mu_list <- numeric(numberOfSimulations)
initial_mu <- mean(input_sample)
numberOfSample <- length(input_sample)
for (i in 1:numberOfSimulations) {
a <- numberOfSample / 2
if (i-1 == 0){
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - initial_mu)^2)))
} else {
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - mu_list[i-1])^2)))
}
bar_y <- mean(input_sample)
# draw from Gamma distribution
h_list[i] <- rgamma(n = 1, shape = a, rate = b)
# draw from Normal distribution
posterior_mean <- ((prior_mean/prior_variance)
+ h_list[i]*numberOfSample*mean(input_sample)) / (1/prior_variance + h_list[i]*numberOfSample)
posterior_variance <- 1 / (1/prior_variance + h_list[i]*numberOfSample)
mu_list[i] <- rnorm(n = 1, mean = posterior_mean, sd = sqrt(posterior_variance))
}
return(list(h=h_list, mu=mu_list))
}
b_prior_mean <- 0
b_prior_variance <- 100^2
b_result <- gibbsSampling_normalPrior(sampleData, b_prior_mean, b_prior_variance)
# Trace plot of µ
df <- data.frame(draw = seq_along(b_result$mu), mu = b_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of normal prior distribution for µ where m_prior = 0, v_prior = 10000)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/b_normalPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(b_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(b_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
b_pValue <- twosided_pvalue(sum_mu_greater_0, sum_mu_less_0)
print(paste('The two-sided p-value is:',b_pValue))
print('Gibbs sampling in case of normal prior distribution for µ')
c_prior_mean <- 0.5
c_prior_variance <- 0.25^2
c_result <- gibbsSampling_normalPrior(sampleData, c_prior_mean, c_prior_variance)
# Trace plot of µ
df <- data.frame(draw = seq_along(c_result$mu), mu = c_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of normal prior distribution for µ where m_prior = 0.5, v_prior = 0.0625)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/c_normalPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(c_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(c_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
c_pValue <- twosided_pvalue(sum_mu_greater_0, sum_mu_less_0)
print(paste('The two-sided p-value is:',c_pValue))
twoSidedTest <- function(input_t) {
if (input_t > -2.2622 & input_t < 2.2622) {
print('t ∈ [-2.2622, 2.2622]: Do not reject the null.')
} else {
print('t ∉ [-2.2622, 2.2622]: Reject the null.')
}
}
t_statistic <- mean(sampleData) / sqrt(var(sampleData)/length(sampleData))
print('A classical/frequentist two-sided test:')
print(paste('Test statistic:', round(t_statistic,4)))
print(paste('The p-value is:', round(t.test(sampleData, alternative = 'two.sided')$p.value,4)))
twoSidedTest(t_statistic)
print('Gibbs sampling in case of flat prior distribution for µ')
sampleData <- c(1.6088,-1.4579,0.4502,1.0701,-0.3803,1.1201,0.4199,0.3998,-0.1904,0.3932)
numberOfSimulations <- 11000
numberOfBurnIn <- 1000
gibbsSampling_flatPrior <- function(input_sample){
h_list <- numeric(numberOfSimulations)
mu_list <- numeric(numberOfSimulations)
initial_mu <- mean(input_sample)
numberOfSample <- length(input_sample)
# Gibbs sampling
for (i in 1:numberOfSimulations) {
a <- numberOfSample / 2
if (i-1 == 0){
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - initial_mu)^2)))
} else {
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - mu_list[i-1])^2)))
}
bar_y <- mean(sampleData)
# draw from Gamma distribution
h_list[i] <- rgamma(n = 1, shape = a, scale = b)
# draw from Normal distribution
mu_list[i] <- rnorm(n = 1, mean = bar_y,
sd = sqrt(1/(h_list[i] * numberOfSample)))
}
return(list(h=h_list, mu=mu_list))
}
a_result <- gibbsSampling_flatPrior(sampleData)
# Trace plot of µ
library(ggplot2)
df <- data.frame(draw = seq_along(a_result$mu), mu = a_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of flat prior distribution for µ)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/a_flatPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
ggplot(df, aes(x = mu)) +
geom_histogram(aes(y = ..density..),
bins = 50, fill = 'skyblue', color = 'black') +
stat_function(fun = dnorm,
args = list(mean = mean(df$mu), sd = sd(df$mu)),
color = 'red', linewidth = 1, linetype = 'dashed') +
geom_vline(xintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(
title = 'Posterior Distribution of µ (in case of flat prior distribution for µ)',
x = 'µ',
y = 'Density'
) +
theme_minimal()
ggsave('figures/a_flatPrior_hist.png', width = 10, height = 6, dpi = 300)
twosided_pvalue <- function(p_pos, p_neg) {
result <- 2 * min(p_pos, p_neg)
result <- min(result, 1)
return(result)
}
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(a_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(a_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
print('Gibbs sampling in case of normal prior distribution for µ')
gibbsSampling_normalPrior <- function(input_sample, prior_mean, prior_variance){
h_list <- numeric(numberOfSimulations)
mu_list <- numeric(numberOfSimulations)
initial_mu <- mean(input_sample)
numberOfSample <- length(input_sample)
for (i in 1:numberOfSimulations) {
a <- numberOfSample / 2
if (i-1 == 0){
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - initial_mu)^2)))
} else {
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - mu_list[i-1])^2)))
}
bar_y <- mean(input_sample)
# draw from Gamma distribution
h_list[i] <- rgamma(n = 1, shape = a, scale = b)
# draw from Normal distribution
posterior_mean <- ((prior_mean/prior_variance)
+ h_list[i]*numberOfSample*mean(input_sample)) / (1/prior_variance + h_list[i]*numberOfSample)
posterior_variance <- 1 / (1/prior_variance + h_list[i]*numberOfSample)
mu_list[i] <- rnorm(n = 1, mean = posterior_mean, sd = sqrt(posterior_variance))
}
return(list(h=h_list, mu=mu_list))
}
b_prior_mean <- 0
b_prior_variance <- 100^2
b_result <- gibbsSampling_normalPrior(sampleData, b_prior_mean, b_prior_variance)
# Trace plot of µ
df <- data.frame(draw = seq_along(b_result$mu), mu = b_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of normal prior distribution for µ where m_prior = 0, v_prior = 10000)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/b_normalPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
ggplot(df, aes(x = mu)) +
geom_histogram(aes(y = ..density..),
bins = 50, fill = 'skyblue', color = 'black') +
stat_function(fun = dnorm,
args = list(mean = mean(df$mu), sd = sd(df$mu)),
color = 'red', linewidth = 1, linetype = 'dashed') +
geom_vline(xintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(
title = 'Posterior Distribution of µ (in case of flat prior distribution for µ)',
x = 'µ',
y = 'Density'
) +
theme_minimal()
ggsave('figures/a_flatPrior_hist.png', width = 10, height = 6, dpi = 300)
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(b_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(b_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
print('Gibbs sampling in case of normal prior distribution for µ')
c_prior_mean <- 0.5
c_prior_variance <- 0.25^2
c_result <- gibbsSampling_normalPrior(sampleData, c_prior_mean, c_prior_variance)
# Trace plot of µ
df <- data.frame(draw = seq_along(c_result$mu), mu = c_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of normal prior distribution for µ where m_prior = 0.5, v_prior = 0.0625)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/c_normalPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
ggplot(df, aes(x = mu)) +
geom_histogram(aes(y = ..density..),
bins = 50, fill = 'skyblue', color = 'black') +
stat_function(fun = dnorm,
args = list(mean = mean(df$mu), sd = sd(df$mu)),
color = 'red', linewidth = 1, linetype = 'dashed') +
geom_vline(xintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(
title = 'Posterior Distribution of µ (in case of flat prior distribution for µ)',
x = 'µ',
y = 'Density'
) +
theme_minimal()
ggsave('figures/a_flatPrior_hist.png', width = 10, height = 6, dpi = 300)
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(c_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(c_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
print('Gibbs sampling in case of flat prior distribution for µ')
sampleData <- c(1.6088,-1.4579,0.4502,1.0701,-0.3803,1.1201,0.4199,0.3998,-0.1904,0.3932)
numberOfSimulations <- 11000
numberOfBurnIn <- 1000
gibbsSampling_flatPrior <- function(input_sample){
h_list <- numeric(numberOfSimulations)
mu_list <- numeric(numberOfSimulations)
initial_mu <- mean(input_sample)
numberOfSample <- length(input_sample)
# Gibbs sampling
for (i in 1:numberOfSimulations) {
a <- numberOfSample / 2
if (i-1 == 0){
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - initial_mu)^2)))
} else {
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - mu_list[i-1])^2)))
}
bar_y <- mean(sampleData)
# draw from Gamma distribution
h_list[i] <- rgamma(n = 1, shape = a, scale = b)
# draw from Normal distribution
mu_list[i] <- rnorm(n = 1, mean = bar_y,
sd = sqrt(1/(h_list[i] * numberOfSample)))
}
return(list(h=h_list, mu=mu_list))
}
a_result <- gibbsSampling_flatPrior(sampleData)
# Trace plot of µ
library(ggplot2)
df <- data.frame(draw = seq_along(a_result$mu), mu = a_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of flat prior distribution for µ)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/a_flatPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
ggplot(df, aes(x = mu)) +
geom_histogram(aes(y = ..density..),
bins = 50, fill = 'skyblue', color = 'black') +
stat_function(fun = dnorm,
args = list(mean = mean(df$mu), sd = sd(df$mu)),
color = 'red', linewidth = 1, linetype = 'dashed') +
geom_vline(xintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(
title = 'Posterior Distribution of µ (in case of flat prior distribution for µ)',
x = 'µ',
y = 'Density'
) +
theme_minimal()
ggsave('figures/a_flatPrior_hist.png', width = 10, height = 6, dpi = 300)
twosided_pvalue <- function(p_pos, p_neg) {
result <- 2 * min(p_pos, p_neg)
result <- min(result, 1)
return(result)
}
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(a_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(a_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
print('Gibbs sampling in case of normal prior distribution for µ')
gibbsSampling_normalPrior <- function(input_sample, prior_mean, prior_variance){
h_list <- numeric(numberOfSimulations)
mu_list <- numeric(numberOfSimulations)
initial_mu <- mean(input_sample)
numberOfSample <- length(input_sample)
for (i in 1:numberOfSimulations) {
a <- numberOfSample / 2
if (i-1 == 0){
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - initial_mu)^2)))
} else {
b <- 1 / (1/2 * sum(sapply(1:numberOfSample,
function(j) (input_sample[j] - mu_list[i-1])^2)))
}
bar_y <- mean(input_sample)
# draw from Gamma distribution
h_list[i] <- rgamma(n = 1, shape = a, scale = b)
# draw from Normal distribution
posterior_mean <- ((prior_mean/prior_variance)
+ h_list[i]*numberOfSample*mean(input_sample)) / (1/prior_variance + h_list[i]*numberOfSample)
posterior_variance <- 1 / (1/prior_variance + h_list[i]*numberOfSample)
mu_list[i] <- rnorm(n = 1, mean = posterior_mean, sd = sqrt(posterior_variance))
}
return(list(h=h_list, mu=mu_list))
}
b_prior_mean <- 0
b_prior_variance <- 100^2
b_result <- gibbsSampling_normalPrior(sampleData, b_prior_mean, b_prior_variance)
# Trace plot of µ
df <- data.frame(draw = seq_along(b_result$mu), mu = b_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of normal prior distribution for µ where m_prior = 0, v_prior = 10000)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/b_normalPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
ggplot(df, aes(x = mu)) +
geom_histogram(aes(y = ..density..),
bins = 50, fill = 'skyblue', color = 'black') +
stat_function(fun = dnorm,
args = list(mean = mean(df$mu), sd = sd(df$mu)),
color = 'red', linewidth = 1, linetype = 'dashed') +
geom_vline(xintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(
title = 'Posterior Distribution of µ (in case of flat prior distribution for µ)',
x = 'µ',
y = 'Density'
) +
theme_minimal()
ggsave('figures/b_flatPrior_hist.png', width = 10, height = 6, dpi = 300)
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(b_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(b_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
print('Gibbs sampling in case of normal prior distribution for µ')
c_prior_mean <- 0.5
c_prior_variance <- 0.25^2
c_result <- gibbsSampling_normalPrior(sampleData, c_prior_mean, c_prior_variance)
# Trace plot of µ
df <- data.frame(draw = seq_along(c_result$mu), mu = c_result$mu)
ggplot(df, aes(x = draw, y = mu)) +
geom_line(color = 'blue') +
geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(title = 'Trace plot of µ (in case of normal prior distribution for µ where m_prior = 0.5, v_prior = 0.0625)',
x = 'Draw', y = 'µ') +
theme_minimal()
ggsave('figures/c_normalPrior_tracePlot.png', width = 10, height = 6, dpi = 300)
ggplot(df, aes(x = mu)) +
geom_histogram(aes(y = ..density..),
bins = 50, fill = 'skyblue', color = 'black') +
stat_function(fun = dnorm,
args = list(mean = mean(df$mu), sd = sd(df$mu)),
color = 'red', linewidth = 1, linetype = 'dashed') +
geom_vline(xintercept = 0, color = 'black', linetype = 'dashed', linewidth = 1) +
labs(
title = 'Posterior Distribution of µ (in case of flat prior distribution for µ)',
x = 'µ',
y = 'Density'
) +
theme_minimal()
ggsave('figures/c_flatPrior_hist.png', width = 10, height = 6, dpi = 300)
# estimate the posterior probabilities
print('The posterior probabilities are:')
sum_mu_greater_0 <- sum(c_result$mu[numberOfBurnIn:numberOfSimulations] > 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ > 0 | y) =', sum_mu_greater_0))
sum_mu_less_0 <- sum(c_result$mu[numberOfBurnIn:numberOfSimulations] < 0)/(numberOfSimulations-numberOfBurnIn)
print(paste('Pr(µ < 0 | y) =', sum_mu_less_0))
y <- c(1.6088, -1.4579, 0.4502, 1.0701, -0.3803, 1.1201, 0.4199, 0.3998, -0.1904, 0.3932)
n <- length(y)
y_bar <- mean(y)
s2 <- sum((y-y_bar)^2) / (n-1)
se <- sqrt(s2/n)
t_stat <- y_bar/se
p_value <- 2*(1-pt(abs(t_stat), df=n-1))
cat("n =", n, "\n")
cat("y_bar =", round(y_bar, 4), "\n")
cat("s2 =", round(s2, 4), "SE =", round(se, 4), "\n")
cat("t = ", round(t_stat, 4), "p-value =", round(p_value, 4), "\n")
critical <- 2.2622
if (abs(t_stat) > critical) {
cat("Reject H0 at 5%", critical, "\n")
} else {
cat("Fail to reject H0 at 5%", critical, "\n")
}
summary_stats <- function(samples){
c(mean=mean(samples), sd=sd(samples), CI_2.5=quantile(samples, 0.025), CI_97.5=quantile(samples, 0.975), p_t0=mean(samples > 0))
}
stats_a <- summary_stats(mu_posterior_a)
